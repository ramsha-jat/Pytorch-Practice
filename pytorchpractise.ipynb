{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\projects\\adam\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in d:\\projects\\adam\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in d:\\projects\\adam\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in d:\\projects\\adam\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\projects\\adam\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\projects\\adam\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\projects\\adam\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\projects\\adam\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in d:\\projects\\adam\\lib\\site-packages (from torch) (75.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\projects\\adam\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\projects\\adam\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in d:\\projects\\adam\\lib\\site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\projects\\adam\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\projects\\adam\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5367, 0.3270, 0.1402, 0.0904, 0.1403],\n",
      "        [0.8983, 0.4773, 0.8297, 0.3019, 0.4264],\n",
      "        [0.6908, 0.0366, 0.1419, 0.0252, 0.7350]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "x = torch.rand(3,5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#check gpu availability\n",
    "print(torch.cuda.is_available())\n",
    "#PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.\n",
    "#DL framework , help to run code faster using gpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #tensor array of numbers which represents data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.Tensor(7)\n",
    "print(scalar.ndim)\n",
    "print(scalar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "vector = torch.tensor([7,7])\n",
    "print(vector.ndim)\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 8],\n",
      "        [4, 6]])\n",
      "2\n",
      "torch.Size([2, 2])\n",
      "tensor([4, 6])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.tensor([[7,8],\n",
    "                     [4,6]])\n",
    "print(matrix)\n",
    "print(matrix.ndim)\n",
    "print(matrix.shape)\n",
    "print(matrix[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "torch.Size([1, 3, 3])\n",
      "3\n",
      "trying different combinations \n",
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "m = torch.tensor([[[1,2,3], [4,5,6], [7,8,9]]])\n",
    "print(m)\n",
    "print(m.shape)\n",
    "print(m.ndim)\n",
    "print(\"trying different combinations \")\n",
    "print(m[0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random tensor\n",
    "r = torch.rand(1,3,4)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.6368e-01, 3.4439e-01, 2.5634e-01,  ..., 5.9213e-01,\n",
      "          6.2377e-01, 5.5124e-01],\n",
      "         [5.2513e-01, 4.6652e-01, 4.1178e-02,  ..., 3.2943e-01,\n",
      "          6.2505e-03, 8.4018e-01],\n",
      "         [1.7166e-01, 4.6423e-01, 1.1011e-01,  ..., 4.1075e-01,\n",
      "          7.8770e-01, 3.5619e-01],\n",
      "         ...,\n",
      "         [3.0107e-01, 4.1206e-01, 2.5907e-01,  ..., 5.0657e-01,\n",
      "          1.4321e-01, 9.2575e-01],\n",
      "         [2.4978e-01, 9.4226e-01, 6.1109e-01,  ..., 3.2590e-01,\n",
      "          2.0269e-01, 5.5346e-01],\n",
      "         [8.9187e-01, 7.2272e-01, 3.0036e-01,  ..., 6.6440e-01,\n",
      "          8.2392e-01, 2.2167e-01]],\n",
      "\n",
      "        [[8.0869e-01, 8.9221e-01, 7.4185e-01,  ..., 1.8768e-01,\n",
      "          4.3045e-01, 3.2924e-01],\n",
      "         [5.5449e-01, 9.2544e-01, 8.7458e-01,  ..., 7.0273e-01,\n",
      "          6.9369e-01, 8.7453e-01],\n",
      "         [5.7842e-01, 4.3991e-01, 4.8115e-01,  ..., 1.5831e-02,\n",
      "          5.2508e-01, 7.5933e-01],\n",
      "         ...,\n",
      "         [5.4826e-01, 5.5923e-01, 4.4275e-01,  ..., 5.0409e-01,\n",
      "          3.8704e-01, 5.9023e-02],\n",
      "         [8.9033e-01, 8.8888e-01, 9.3544e-01,  ..., 9.0210e-01,\n",
      "          4.5841e-01, 6.8631e-01],\n",
      "         [8.4933e-02, 2.8563e-01, 8.0392e-01,  ..., 9.8822e-02,\n",
      "          3.4604e-01, 1.7049e-01]],\n",
      "\n",
      "        [[4.6023e-01, 4.4554e-01, 3.2931e-01,  ..., 3.3570e-01,\n",
      "          6.1277e-01, 6.3647e-01],\n",
      "         [2.8881e-01, 6.0742e-01, 8.4475e-01,  ..., 3.0732e-04,\n",
      "          8.8965e-01, 9.8444e-02],\n",
      "         [5.3301e-02, 7.8194e-01, 2.1506e-01,  ..., 1.6389e-01,\n",
      "          7.1308e-02, 2.4126e-01],\n",
      "         ...,\n",
      "         [6.4971e-01, 5.0468e-01, 2.0942e-01,  ..., 8.8096e-01,\n",
      "          6.4281e-01, 4.3586e-01],\n",
      "         [6.4185e-01, 2.5386e-01, 9.4874e-01,  ..., 2.0154e-01,\n",
      "          1.3350e-01, 9.9250e-01],\n",
      "         [7.0974e-01, 5.0443e-01, 3.9389e-01,  ..., 1.2892e-01,\n",
      "          9.8799e-02, 2.0896e-01]]])\n",
      "torch.Size([3, 244, 244])\n",
      "3\n",
      "tensor(0.4812)\n"
     ]
    }
   ],
   "source": [
    "img = torch.rand(size=(3,244,244))\n",
    "print(img)\n",
    "print(img.shape)\n",
    "print(img.ndim)\n",
    "print(img[1,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.float32\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#zeros and ones tensor\n",
    "zeros = torch.zeros(size=(3,3))\n",
    "print(zeros)\n",
    "print(zeros.dtype)\n",
    "ones = torch.ones(size=(3,3))\n",
    "print(ones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a range"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Adam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
